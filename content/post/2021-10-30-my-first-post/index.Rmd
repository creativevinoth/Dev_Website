---
title: My first post
author: ''
date: '2021-11-11'
slug: Bank
---
```{r message = FALSE, warning = FALSE, echo = FALSE}

library(ggplot2)
library(dplyr)
library(data.table)
library(tidyr)
library(GGally)
library(gapminder)
library(tidyverse)
library(pastecs)
library(ggpubr)
library(fastDummies)
library(QuantPsyc)
library(MASS)
library(caret)
library(leaps)
library(summarytools)
library(epiDisplay)
library(tidymodels)
library(Rmisc)
library(SIBER)
```


```{r message = FALSE, warning = FALSE, echo = FALSE, include = FALSE}
bank <- read.csv("bank.csv")
```

The report of logistic regression on bank data set to answer if customer will subscribe term deposit or not


## Table of contents

Executive summary

Issues and Challanges

Univariate analysis on metric and nonmetric data

Bivariate analysis

Logistic regression using tidymodels

Workflow and model creation with cross validation

Manual logistic regression

Bootstrap method

Observation and comments

References




## Executive sumamry

The portuguese banking institution has a product term deposit. The data was collected in a direct marketing campaign based on phone calls. They would like to know if the customers would subscribe to the term deposit or not. The age, balance, day, duration, campaign, pdays and previous are numerical data. The job, marital, education, contact, poutcome are nominal categorical values.I consider the following variables as binary categorical values such as default, housing, loan, y and assigned o and 1. Y is the outcome and response variable. I consider month as a ordinal categorical value and i assign sequential numbers from 1 to 12 respective to a month.

Initially, univariate analysis was performed to remove the outliers. Boxplot was graphed to find out the outliers. Bivariate analysis was performed to find out if there is any correlation between dependant and independant variable and find out the equation is significant or not. Using tidymodels, feature engineering was used to preprocess data and then used logistic regressing to fit the model and cross validation was done and used confusion matrix to validate the results. Then I used workflow model to automate and use the model for new data set. I have also done manual logistic regression model.

It was clear that customers will not subscribe for the term deposit. The bank has to take some steps whereby stimulate the customers such as increasing rate of interest or offering some better additional offers like providing a health insurance free for term deposit of some amount.


# Issues and challanges

The greatest challange for the bank is to find out which all variables to be considered to arrive at an outcome that if customers will subscribe to term deposit or not. There are some categorical variables, for twhich dummy values to be assigned. There are some binary categorical values and binary to be assigned and there is some ordianal categorical values, those can be considered as a numerical values by assigning a sequential values to it. After identifying the factors which influence most for sunscribing to the term deposit, marketing efforts should be directed towards the same to rope in more term deposit.



# Structure of the data set
```{r}
str(bank)
```

# Descriptive statistics of numerical independent values

```{r}
descr(bank)
```
# Summary of dataset
```{r}
summary(bank)
```
# Data table of data set

```{r}
data.table(bank)
```
## Univariate analysis on numerical data

# Univariate analysis on age

```{r}
descr(bank$age)
```
The minimum age of the customer is 19 and maximum age is 87. There is a standard deviation of 10.58, which is high in numbers. Let me dwar a box plot to find out the outliers so that data can be streamlined and standard deviation can be reduced

# Box plot of age and its outliers

```{r}
age_outliers<-boxplot.stats(bank$age)$out
boxplot(bank$age, main = "Box plot of age", boxwex = 0.6)
mtext(paste("Outliers: ", paste(age_outliers, collapse =", ")), cex = 0.6)
age_outliers
```

We can see the outliers of the age lie between 74 and 87.

# Minimum value of age outliers

```{r}
min(age_outliers)
```
# Maximum value of age outliers

```{r}
max(age_outliers)
```
I used subset function to add the age less than 74 so that outliers can be removed

```{r}
bank<- subset(bank, age < 74)
```

# Boxplot of age after removal of outliers

```{r}
age_withoutoutliers<-boxplot.stats(bank$age)$out
boxplot(bank$age, main = "Box plot of age after reomval of outliers", boxwex = 0.6)
mtext(paste("Outliers: ", paste(age_withoutoutliers, collapse =", ")), cex = 0.6)
age_withoutoutliers
```


# Univariate analysis on balance

```{r}
descr(bank$balance)
```
The minimum balance of the customer is -3313, which is a negative balance because of non maintenance charges or some other charges. The maximum balance is 71188. The standard deviation is 2987 and median is 440.

# Box plot of balance and its outliers

```{r}
balance_outliers<-boxplot.stats(bank$balance)$out
boxplot(bank$balance, main = "Box plot of balance", boxwex = 0.6)
mtext(paste("Outliers: ", paste(balance_outliers, collapse =", ")), cex = 0.6)
balance_outliers
```
We can see more outliers in balance. The outliers ranges between -3313 and 0 and between 267 and 71188


# Minimum negative value of balance outlier

```{r}
min(balance_outliers)
```
# Minimum positive value of balance outlier
```{r}
which.min(balance_outliers>0)
```
# Maximum value of balance outlier

```{r}
max(balance_outliers)
```
The outliers are removed by choosing the value between 0 and 273
```{r}
bank<- subset(bank, balance > 0 & balance < 273)
```

# Boxplot of balance after removal of outliers
```{r}
balance_withoutoutliers<-boxplot.stats(bank$balance)$out
boxplot(bank$balance, main = "Box plot of balance after removal of outliers", boxwex = 0.6)
mtext(paste("Outliers: ", paste(balance_withoutoutliers, collapse =", ")), cex = 0.6)
balance_withoutoutliers
```


# Unvariate analysis on day

```{r}
descr(bank$day)
```

The minimum contact day is 1 and maximum is 31. There is a standard deviation of 8.41


# Boxplot of day after removal of outliers

```{r}
day_outliers<-boxplot.stats(bank$day)$out
boxplot(bank$day, main = "Box plot of day", boxwex = 0.6)
mtext(paste("Outliers: ", paste(day_outliers, collapse =", ")), cex = 0.6)
day_outliers
```
There are no outliers in day


# Univariate analysis on duration

```{r}
descr(bank$duration)
```

The minimum contact duration was 5 seconds and maximum duration was 2456 seconds. There is a standard deviation of 234.81 seconds

# Box plot of duration and its outliers

```{r}
duration_outliers<-boxplot.stats(bank$duration)$out
boxplot(bank$duration, main = "Box plot of duration", boxwex = 0.6)
mtext(paste("Outliers: ", paste(duration_outliers, collapse =", ")), cex = 0.6)
duration_outliers
```
There are some outliers in duration, ranging between 597 and 2456 seconds


# Minimum value of duration outlier

```{r}
min(duration_outliers)
```
# Maximum value of duration outlier

```{r}
max(duration_outliers)
```

The outliers are removed greater then 597 using subset
```{r}
bank<- subset(bank, duration < 597)
```

# Boxplot of duration after removal of outliers

```{r}
duration_withoutoutliers<-boxplot.stats(bank$duration)$out
boxplot(bank$duration, main = "Box plot of duration after outliers are removed", boxwex = 0.6)
mtext(paste("Outliers: ", paste(duration_withoutoutliers, collapse =", ")), cex = 0.6)
duration_withoutoutliers
```



# UNivariate analysis on campaign

```{r}
descr(bank$campaign)
```
# Box plot of Campaign

```{r}
campaign_outliers<-boxplot.stats(bank$campaign)$out
boxplot(bank$campaign, main = "Box plot of campaign", boxwex = 0.6)
mtext(paste("Outliers: ", paste(campaign_outliers, collapse =", ")), cex = 0.6)
campaign_outliers
```
There are many outliers in campaign ranging between 7 and 31

# Minimum of campaign outliers

```{r}
min(campaign_outliers)
```
# Maximum of campaign outliers

```{r}
max(campaign_outliers)
```
The outliers are removed and data are taken less than 7

```{r}
bank<- subset(bank, campaign < 7)
```

# Box plot of campaign after removal of outliers

```{r}
campaign_withoutoutliers<-boxplot.stats(bank$campaign)$out
boxplot(bank$campaign, main = "Box plot of campaign after removal of outliers", boxwex = 0.6)
mtext(paste("Outliers: ", paste(campaign_withoutoutliers, collapse =", ")), cex = 0.6)
campaign_withoutoutliers
```

# Box plot of pdays

```{r}
pdays_outliers<-boxplot.stats(bank$pdays)$out
boxplot(bank$pdays, main = "Box plot of pdays", boxwex = 0.6)
mtext(paste("Outliers: ", paste(pdays_outliers, collapse =", ")), cex = 0.6)
pdays_outliers
```
It is surprising to see that whole data are outliers.

# Minimum of pdays outliers

```{r}
min(pdays_outliers)
```
# Maximum of pdays outliers

```{r}
max(pdays_outliers)
```
The whole coloum pdays is removed from dataset because of outliers high in numbers

```{r}
bank<- subset(bank, select = -pdays)
```



# Box plot of previous

```{r}
previous_outliers<-boxplot.stats(bank$previous)$out
boxplot(bank$previous, main = "Box plot of previous", boxwex = 0.6)
mtext(paste("Outliers: ", paste(previous_outliers, collapse =", ")), cex = 0.6)
previous_outliers
```
Even the previous data has full outliers on data. Thus, I removed it from the dataset

# Minimum of previous outliers

```{r}
min(previous_outliers)
```
# Maximum outliers

```{r}
max(previous_outliers)
```
The whole column of previous is removed from the bank dataset due to more outliers

```{r}
bank<- subset(bank, select = -previous)
```


## Univariate analysis on categorical value

# Frequency distribution of job


```{r}
tab1(bank$job, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of job", xlab ="Job")
```
The frequency distribution of unknown, student, unemployed, housemaid, retired, entrepreneur, self-employed, services, admin are less in numbers. Thus they are are clubbed together as others so as to reduce the number of variables and improve the prediction accuracy

```{r}
bank$job<-as.character(bank$job)
bank$job[bank$job %in% c("unknown", "student", "housemaid", "unemployed", "entrepreneur", "self-employed", "retired", "services", "admin.")]<- "Others"
bank$job<-as.factor(bank$job)
```

# The frequency distribution after clubing together

```{r}
freq_age_updated <-tab1(bank$job, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of job after merging", xlab ="Job")
freq_age_updated
```



# Frequency distribution of marital

```{r}
tab1(bank$marital, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of marital", xlab ="Marital")
```
The frequency distribution of all items are greater than 10 percent. So, we are not doing any changes

# frequency distribution of Education

```{r}
tab1(bank$education, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Education", xlab ="Education")
```
The frequency distribution of unknown in education is less than5 percent. Thus, they are merged with primary.


```{r}
bank$education<-as.character(bank$education)
bank$education[bank$education %in% c("unknown", "primary")]<- "primary and others"
bank$education<-as.factor(bank$education)

```

# Frequency distribution of education after merging

```{r}
freq_education_updated<- tab1(bank$education, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Education after merging", xlab ="Education")
freq_education_updated
```


# Frequency distribution of Contact

```{r}
tab1(bank$contact, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Contact", xlab ="Contact")
```
The frequency of the telephone is only 5.5%, Thus, I add those values with unknowna and renamed it as telephone and others

```{r}
bank$contact<-as.character(bank$contact)
bank$contact[bank$contact %in% c("telephone", "unknown")]<- "telephone and others"
bank$contact<-as.factor(bank$contact)
```

# Frequency distribution of contact after merging

```{r}
freq_contact_updated <- tab1(bank$contact, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Contact after merging", xlab ="Contact")
freq_contact_updated
```


# Frequency distribution of poutcome

```{r}
tab1(bank$poutcome, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of poutcome", xlab ="poutcome")
```
The frequency distribution of success and others are less in percentage. So, I combined both into one category and renamed it as success and others

```{r}
bank$poutcome<-as.character(bank$poutcome)
bank$poutcome[bank$poutcome %in% c("success", "other")]<- "success and others"
bank$poutcome<-as.factor(bank$poutcome)
```

# Frequenct distribution of poutcome after merging

```{r}
freq_poutcome_updated<-tab1(bank$poutcome, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of poutcome after merging", xlab ="poutcome")
freq_poutcome_updated
```


considering the below as a Binary variables and binary numbers o and 1 are assigned

Assigning binary numbers to default

```{r}
bank$default[bank$default == "no" ] <-"0"
```

```{r}
bank$default[bank$default == "yes" ] <-"1"
```

Assigning binary numbers to Housing

```{r}
bank$housing[bank$housing == "no" ] <-"0"
bank$housing[bank$housing == "yes" ] <-"1"
```

Assigning binary numbers to loan

```{r}
bank$loan[bank$loan == "no" ] <-"0"
bank$loan[bank$loan == "yes" ] <-"1"
```

Assigning binary numbers to y

```{r}
bank$y[bank$y == "no" ] <-"0"
bank$y[bank$y == "yes" ] <-"1"
```


COnsidering the month as a ordinal categorical variable, I assign the numbers in a sequantial order

```{r}
bank$month[bank$month == "jan" ] <-"1"
bank$month[bank$month == "feb" ] <-"2"
bank$month[bank$month == "mar" ] <-"3"
bank$month[bank$month == "apr" ] <-"4"
bank$month[bank$month == "may" ] <-"5"
bank$month[bank$month == "jun" ] <-"6"
bank$month[bank$month == "jul" ] <-"7"
bank$month[bank$month == "aug" ] <-"8"
bank$month[bank$month == "sep" ] <-"9"
bank$month[bank$month == "oct" ] <-"10"
bank$month[bank$month == "nov" ] <-"11"
bank$month[bank$month == "dec" ] <-"12"
```

Converting binary and ordinal categorical variable to numeric to perform univariate analysis as a numerical variable

```{r}
bank$default <- as.numeric (bank$default)
bank$housing <- as.numeric (bank$housing)
bank$loan <- as.numeric (bank$loan)
bank$y <- as.numeric (bank$y)
bank$month <- as.numeric (bank$month)

```


## Univariate analysis on the binary variables

# Frequency distribution of Default


```{r}
tab1(bank$default, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Default", xlab ="Default")
```
There are only 2 percentage of customers did default on loan and the rest 98 percent of customers are not defaulters

# Frequency distribution of housing

```{r}
tab1(bank$housing, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Housing", xlab ="Housing")
```
The customers who have taken housing loan are 53.8 percentage and the other 46.2 percentage of customers did not take any housing loan


# Frequency distribution of Loan

```{r}
tab1(bank$loan, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Loan", xlab ="Loan")
```
Only 16.7 % of customer took a personal loan and the remaining 83.3 % of customer did not avail any personal loan


# Frequency distribution of y


```{r}
tab1(bank$y, sort.group = "increasing", cum.percent = TRUE, main = "Frequency distribution of Y", xlab ="Y")
```
The majority of the customer, around 93.2 %, said that they would not subscribe to term deposit. Only 6.8 % of customers confirmed that they would subscribe it.


# Box plot of Month


```{r}
month_outliers<-boxplot.stats(bank$month)$out
boxplot(bank$month, main = "Box plot of Month", boxwex = 0.6)
mtext(paste("Outliers: ", paste(month_outliers, collapse =", ")), cex = 0.6)
month_outliers
```




## Bivariate analysis

Let us see the relationship between indendent and dependent variable


# Relationship between y and age

# Correlation test
```{r}
cor.test(bank$y, bank$age)
```
There is a negative correlation between y and age. It means more the age, less the people will subscribe to fixed deposit and less the age of the customer and there is a more likely that they will subscribe to term deposit. The correlation coefficient is -0.051

# Logistic regression on y and age

```{r}
age_y = glm(y~ age, data = bank, family = "binomial")
summary(age_y)
```
The above equation is not significant

# Jitter and box plot of y and age

```{r}
bank %>%
  ggplot(aes(x= age, y= "subscribe or not", color = age))+geom_jitter()+geom_boxplot()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and age")
```

# Relationship between y and job

Logistic regression on y and job

```{r}
job_y = glm(y~ job, data = bank, family = "binomial")
summary(job_y)
```
The above equation is not good enough to predict the y by job as some of the coefficients are not significant

# Bar chart of y and job

```{r}
bank %>%
ggplot(aes(x= job, y= "subscribe or not", color = job))+geom_col()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and job")+coord_flip()
```

## Relationship between y and marital

Logistic regression on y and marital

```{r}
marital_y = glm(y~ marital, data = bank, family = "binomial")
summary(marital_y)
```
the above equation is not good as well because of all the coefficients are not significant

# Bar chart of y and marital

```{r}
bank %>%
ggplot(aes(x= marital, y= "subscribe or not", color = marital))+geom_col()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and marital")
```

# Relationship between y and Education

Logistic regression on y and education

```{r}
education_y = glm(y~ education, data = bank, family = "binomial")
summary(education_y)
```
The intercept is only significant but all the coefficients are not significant. Thus, the above equation is not good to predict the y

# Bar chart of y and education

```{r}
bank %>%
ggplot(aes(x= education, y= "subscribe or not", color =education))+geom_col()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and education")
```


# Relationship between y and default

Correlation between y and default

```{r}
cor.test(bank$y, bank$default)
```
There is some correlation between y and default. The correlation coefficient is 0.056

# Logistic regression on y and default

```{r}
default_y = glm(y~ default, data = bank, family = "binomial")
summary(default_y)
```
Though there is some correlation between y and default, the coefficient of the above equation is not significant.

# Bar chart of y and default

```{r}
bank %>%
ggplot(aes(x= default, y= "subscribe or not", colour= default))+geom_col()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial", maxit =100))+labs(title ="Relationship between y and default")
```

# Relationship between y and balance

```{r}
cor.test(bank$y, bank$balance)
```
There is some positive correlation between y and balance. The correlation coefficient is 0.016

# Logistice regression on y and balance

```{r}
balance_y = glm(y~ balance, data = bank, family = "binomial")
summary(balance_y)
```
Even though there is a positive correlation between y and balance, that above equation is not good as the coefficient is not significant

# JItter and box plot of y and balance

```{r}
bank %>%
ggplot(aes(x= balance, y= "subscribe or not", color =balance))+geom_jitter()+geom_boxplot()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and balance")
```


## Relationship between y and housing

Correlation test between y and housing

```{r}
cor.test(bank$y, bank$housing)
```
There is a negative correlation between y and housing. The correlation coefficient is -0.083

# Logistic regression of y and housing

```{r}
housing_y = glm(y~ housing, data = bank, family = "binomial")
summary(housing_y)
```
The above equation is significant to predict y but it is a negative correlation. If the customer takes more housing loan, it is less likely that he will subscribe to term  deposit because he would have already a commitment to oay a monthly EMI. On the contrary, if the customer does not have any housing loan, it is more likely that he will subscribe to term deposit

# Bar chart of y and housing

```{r}
bank %>%
ggplot(aes(x= housing, y= "subscribe or not", colour = housing))+geom_col()+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial", maxit =100))+labs(title ="Relationship between y and housing")
```
In the above chart, o represents no housing loan and 1 represents customer having housing loan. 


# Relationship between y and loan

Correlation test of y and loan

```{r}
cor.test(bank$y, bank$loan)
```
There is a negative correlation between y and loan. It is just like the case of housing loan. When the customers have an obligation towards personal loan, they will not have the sufficients funds to subscribe to term deposit. That is the reason, there is a negative correlation. When the customer does not have personal loan, there is a likely chance that they will subscribe to term deposit.

# Logistic regression of y and loan
```{r}
loan_y = glm(y~ loan, data = bank, family = "binomial")
summary(loan_y)
```
The above equation is to significant to predict the y. The AIC is 457.62



# Bar chart of y and loan
```{r}
bank %>%
ggplot(aes(x= loan, y= "subscribe or not", colour =loan))+geom_col()+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial", maxit =100))+labs(title ="Relationship between y and loan")
```

# Relationship between y and contact

Logistic regression of y and contact

```{r}
contact_y = glm(y~ contact, data = bank, family = "binomial")
summary(contact_y)
```
The above equation is significant to predict y. The AIC is 443.3

# Bar chart of y and contact
```{r}
bank %>%
ggplot(aes(x= contact, y= "subscribe or not", colour =contact))+geom_col()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and contact")
```

# Relationship between y and day

Correlation test of y and day

```{r}
cor.test(bank$y, bank$day)
```
There is a positive correaltion between y and day

# Logistic regression of y and day
```{r}
day_y = glm(y~ day, data = bank, family = "binomial")
summary(day_y)
```
Though there is a correlation between y and day, the above equation is not significant.

# Jitter and box plot of y and day

```{r}
bank %>%
ggplot(aes(x= day, y= "subscribe or not", color =day))+geom_jitter()+geom_boxplot()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and day")
```

# Relationship between y and month

Correlation between y and month

```{r}
cor.test(bank$y, bank$month)
```
There is a negative correlation. The correlation coefficient is - 0.004

# Logistic regression on y and month

```{r}
month_y = glm(y~ month, data = bank, family = "binomial")
summary(month_y)
```
The above equation is not good as the coefficient is not significant

# Bar chart of y and month

```{r}
bank %>%
ggplot(aes(x= month, y= "subscribe or not", color =month))+geom_col()+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial",maxit =100))+labs(title ="Relationship between y and month")
```


## Relationship between y and duration

Correlation test of y and duration

```{r}
cor.test(bank$y, bank$duration)
```
There is a positive correlation between y and duration. The correlation coefficient is 0.23

# Logistic regression of y and duration
```{r}
duration_y = glm(y~ duration, data = bank, family = "binomial")
summary(duration_y)
```
The above equation is significant to predict y. The AIC is 423.13

# Box plot of y and duration

```{r}
bank %>%
ggplot(aes(x= duration, y= "subscribe or not", color =duration))+geom_boxplot()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and duration")
```

# Relationship between y and campaign

Correlation test between y and campaign

```{r}
cor.test(bank$y, bank$campaign)
```
It is surprising to see that there is a negative correlation between y and campaign. Generally, more the campaign, more should be a new subscription of term deposit but it is opposite here


# Logistic regression between y and campaign
```{r}
campaign_y = glm(y~ campaign, data = bank, family = "binomial")
summary(campaign_y)
```
The above equation is significant to predict the y because both the intercept and coefficient are significant. The AIC is 458.53

# box plot of Campaign

```{r}
bank %>%
ggplot(aes(x= campaign, y= "subscribe or not", color =campaign))+geom_boxplot()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and campaign")
```




# Relationship between y and poutcome

Logistic regression of y and poutcome

```{r}
poutcome_y = glm(y~ poutcome, data = bank, family = "binomial")
summary(poutcome_y)
```
In the above equation, one of the coefficient is not significant. We can take this in to our model since unknow result are more compared to known factors such as success or failure. There is a great chance to convert those customers in to subscribe the term deposit

# Bar chart of y and poutcome

```{r}
bank %>%
ggplot(aes(x= poutcome, y= "subscribe or not", color =poutcome))+geom_col()+expand_limits(y=0)+geom_smooth(method ="glm", se =FALSE, method.args = list(family = "binomial"))+labs(title ="Relationship between y and poutcome")
```

First, I would use tidymodels to build a logistic regression. In order to do, I have to convert the following as a character variable

```{r}
bank$default <- as.character (bank$default)
bank$housing <-  as.character (bank$housing)
bank$loan <-  as.character (bank$loan)
bank$y <-  as.character (bank$y)
bank$month <-  as.character (bank$month)
```



# Data resampling
I have split the bank data in to trainig and test data with a split of 75:25
```{r}
bank_split<- initial_split(bank, prop = 0.75, strata = y)
bank_training <- bank_split %>%
  training()
bank_test<- bank_split %>%
  testing()
```

# Checking number of rows in training and test data

```{r}
nrow(bank_training)
nrow(bank_test)
```
# Checking multicollinearity between numerical values in a training bank data set

```{r}
bank_training %>%
  select_if(is.numeric) %>%
  cor()
```
We can notice that there is no much corellation the independent variable


# Model specification
I specify the logistic regression model here
```{r}
logistic_model<- logistic_reg() %>%
  set_engine('glm') %>%
  set_mode('classification')
```

# Feature engineering

This is step to do pre-processing of data
```{r}
bank_recipe <- recipe(y ~., data = bank_training) %>%
  step_corr(all_numeric(), threshold =0.8) %>%
  step_normalize(all_numeric()) %>%
  step_dummy(all_nominal(), -all_outcomes())
bank_recipe
```
I have given instruction above in the model that to check the correlation for all numeric variables and keep the thresholding limit as 0.8. I have also given instruction in the model to normalize all the numeric variables and set dummy to all nominal or character variables except the outcome variables because outcome is in factor


# Recipe training

```{r}
bank_recipe_prep<- bank_recipe %>%
  prep(training = bank_training)
bank_recipe_prep
```
## Preprocess training data
Applying the trained recipe to the training data

```{r}
bank_training_prep <- bank_recipe_prep %>%
  bake (new_data = NULL)
bank_training_prep
```
## Preprocess test data
Applying trained recipe to the test data

```{r}
bank_test_prep <- bank_recipe_prep %>%
  bake (new_data = bank_test)
bank_test_prep
```

# Model fitting

```{r}
logistic_fit <- logistic_model %>%
  fit(y ~., data = bank_training_prep)
logistic_fit
```
The above is the significant equation to predict the outcome variable. The AIC is 289.2, which is quite good compared to our manual method


# Predicting outcome categories

```{r}
class_preds <- predict (logistic_fit, new_data = bank_test_prep, type ="class")
class_preds
```
The above .pred class is the outcome of our results. That is if the customer is to subscribe to term deposit or not. The number o means no and 1 means yes to subscriptions

# Estimated probabilities

```{r}
prob_preds <- predict (logistic_fit, new_data = bank_test_prep, type ="prob")
prob_preds
```

The above prediction is the probability of outcome occurences.


In tidymodels, outcome variable needs to be a factor
```{r}
bank$y <- as.factor (bank$y)
```

# Combining results

```{r}
results <- bank_test_prep %>%
  bind_cols(class_preds, prob_preds)
results
```
I was trying to select only y and show the .pred_class and .pred probability to show how much actual and prediction class and its probability but when i used select (y) %>%, I was getting error, so I show here the whole model with .pred class and its probability at the end of the table


# Assessing the model fit using Confusion matrix


```{r}
results %>%
  conf_mat(truth = y, estimate = .pred_class)
```
# Correct predictions
True negative is 220, which is the customer did not subscibe to term deposit
True positive is 2, which is the customers subscripe to term deposit

# Classification error

False negative is 5, which is the customer did not subscribe to term deposit but wrongly predicted as subscriped
False positive is 9, which is the customer subscribed to term deposit but wronly predicted as not subscribed

It is clear that the customers will not subscribe to the term deposit


In order to automate this logistic regression model in machine learning, I have created the following workflow models


# Creating workflow

```{r}
bank_wkfl<- workflow() %>%
add_model(logistic_model) %>%
add_recipe(bank_recipe)
bank_wkfl
```
I have given instruction above in the model that to check the correlation for all numeric variables and keep the thresholding limit as 0.8. I have also given instruction in the model to normalize all the numeric variables and set dummy to all nominal or character variables except the outcome variables because outcome is in factor


# Train the workflow

```{r}
bank_wkfl_fit <- bank_wkfl %>%
  last_fit( split = bank_split)
bank_wkfl_fit
```

# Calculating performance metrics on test data

```{r}
bank_wkfl_fit %>%
   collect_metrics() 
```

# collecting predictions

```{r}
bank_wkfl_fit_results<- bank_wkfl_fit %>%
  collect_predictions()
bank_wkfl_fit_results
```


# Creating custom metrics

```{r}
bank_metrics <- metric_set(roc_auc,sens,spec)
bank_metrics
```
```{r}
bank_wkfl_fit_results %>%
  bank_metrics(truth = y, estimate = .pred_class, .pred_1)
```
# Creating cross validation folds
Bank training data has been splited into 5 fold using cross validation 

```{r}
set.seed(315)
bank_folds<- vfold_cv(bank_training, v = 5, strata = y)
bank_folds
```

# Fit resamples

```{r}
bank_rs <- bank_wkfl %>%
  fit_resamples(resamples = bank_folds, metrics = bank_metrics)
bank_rs %>%
  collect_metrics()
```
The roc_auc is 0.76
The sensitivity is 0.98, which is the proportion of positive cases that were correctly classified
The secificity is 0.19, which is the proportion of negative cases that were correctly classified


# Detailed cross validation results

```{r}
bank_detailed_results <- bank_rs %>%
  collect_metrics(summarize = FALSE)
bank_detailed_results
```
# Summarizing cross validation results

```{r}
bank_detailed_results %>%
   group_by(id) %>%
  filter(.metric == 'roc_auc') %>%
 summarize(min = min(.estimate),
            median = median(.estimate),
            max = max(.estimate), mean = mean (.estimate),
            sd = sd(.estimate)
           )
```

# Viewing the best performing models

```{r}
bank_rs %>%
  show_best(metric = 'roc_auc', n=5)
```
```{r}
best_bank_model <- bank_rs %>%
  select_best(metric = 'roc_auc')
best_bank_model 
```

We have got the best model as Preprocessor1_Model1

# Finalizing the workflow

```{r}
final_bank_wkfl <- bank_wkfl %>%
finalize_workflow(best_bank_model)
final_bank_wkfl
```
# Model fitting

```{r}
bank_final_fit <- final_bank_wkfl %>%
  last_fit(split = bank_split)
bank_final_fit %>%
  collect_metrics()
```
We can see here this model is good to predict and ready to use the same model to predic anynew data set. Its accuracy is 0.94 and roc_auc is 0.88

# Model evaluation

```{r}
bank_wkfl_fit_results  %>%
  conf_mat(truth = y, estimate = .pred_class)
```
# Correct predictions
True negative is 220, which is the customer did not subscibe to term deposit
True positive is 3, which is the customers subscripe to term deposit

# Classification error

False negative is 3, which is the customer did not subscribe to term deposit but wrongly predicted as subscriped
False positive is 10, which is the customer subscribed to term deposit but wronly predicted as not subscribed

It is clear that the customers will not subscribe to the term deposit



Converting character to factor to run logistic regression so that I can run below the manual logistic regression using glm function

```{r}
bank$default <- as.factor (bank$default)
bank$housing <- as.factor (bank$housing)
bank$loan <- as.factor (bank$loan)
bank$y <-  as.factor (bank$y)
bank$month <- as.factor (bank$month)
bank$job <- as.factor (bank$job)
bank$marital <- as.factor (bank$marital)
bank$education <- as.factor (bank$education)
bank$poutcome <- as.factor (bank$poutcome)
bank$contact <- as.factor (bank$contact)
```

# Structure of bank after applying factor
```{r}
str(bank)
```
# Summary after changing the factor variable

```{r}
summary(bank)
```


# Best subset regression
```{r}
best<-regsubsets(y~ ., data= bank, nvmax= 14)
summary(best)
```


# Logistic regression on full model

```{r}
fullmodel = glm(y~., data = bank, family = "binomial")
summary(fullmodel)
```

The full model is not good as many of the coefficients are not significant

After a many trials, the following is the best model

# Backward regression
The following is the best model by backward regression
```{r}

mod_step<- stepAIC(fullmodel, direction = 'backward', trace = FALSE)
mod_step
```

# Bootstrap method
Using bootstrap re sampling with replacement method to access the consistency predictors selected with stepwise
```{r message = FALSE, warning = FALSE, echo = FALSE}
library(bootStepAIC)
```
```{r message = FALSE, warning = FALSE, echo = FALSE}
mod_boot<- boot.stepAIC(fullmodel, bank, B =50)
```

## Bootstrap summary

```{r}
print(mod_boot)
```

# Best model by bootstrap method
```{r}
best_bootmodel <- glm(y ~ default + loan + contact + month + duration + campaign + poutcome, data = bank, family = "binomial")
summary(best_bootmodel)
```
We can see still many coefficients are significant. 

# Odds ratio
```{r}
bank_or <- data.frame(exp(best_bootmodel$coefficients))
bank_or
```
# produce percentage odds
```{r}
bank_or_perc<- (bank_or-1)*100
bank_or_perc
```
The above percentage shows that positive values are that much percentage chance that customer will subscribe to term deposit and negative values are that there are less chance of subscribing to term deposit
```{r message = FALSE, warning = FALSE, echo = FALSE}
library(car)

```
# Multicolinearity

```{r}
vif(best_bootmodel)
```

# Best model

After many iterations, below are the best model to predict the classification models

```{r}
best <- glm(y~ contact+duration+loan+campaign,  data = bank, family = "binomial")
summary(best)
```
## Multicolinearity analysis
```{r}
vif(best)
```
The above is evident that there is no multi-colinearity among the variables

The above model is significant

The contact, duration, loan and campaign are the best predictors

I have done this manual logistic regression after the machine learning automated logsitic regression.


As per the above manual and tidymodels logistic regresssion, it was evident from the confusion matric that majority of the customers are predicted that they will not subscribe to term deposit



## Observations and comments

1. The important determinants of the subscription to term deposit are contact, duration, loan and campaign.

2. Though balance, day and default had positive correlation, it failed to get significance in a whole equation

3. They failed to include the main determinants such as rate of interest, tenure of the term deposit, flexibility of foreclosure, etc which are the main influence for the customer to subscribe to term deposit

4. All the character variables are assigned as a factor and few of the ordinal categorical variables are assigned a number

5. cross validation and boot strapping methods used for re sampling technique.

6. Based on the outcome, bank should stop targeting those who has any loan as they wont be able to subscribe to term deposit due to fixed monthly obligations by loan EMI

7. Bank should keep doing marketing campaign as that will eventually gain a good business, if not immediately, at least in future.


## References

[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014
https://archive.ics.uci.edu/ml/datasets/Bank+Marketing



